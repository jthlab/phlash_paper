import numpy as np
import pandas as pd
import tqdm.auto as tqdm

from itertools import product
from collections import defaultdict
import matplotlib.transforms as mtransforms
from functools import cache

import cyvcf2
import stdpopsim

from phlash.sim import _get_N0, _find_stdpopsim_model


wildcard_constraints:
    n=r"\d+",
    i=r"\d+",
    j=r"\d+",


H2H_PARAMS = {
    "models": [
        ("HomSap", stdpopsim.PiecewiseConstantSize(1e4), "pop_0"),
        ("AnoGam", "GabonAg1000G_1A17", "GAS"),
        ("AraTha", "SouthMiddleAtlas_1D17", "SouthMiddleAtlas"),
        ("AraTha", "African3Epoch_1H18", "SouthMiddleAtlas"),
        ("BosTau", "HolsteinFriesian_1M13", "Holstein_Friesian"),
        ("DroMel", "African3Epoch_1S16", "AFR"),
        # ("DroMel", "OutOfAfrica_2L06", "AFR"),
        ("HomSap", "AmericanAdmixture_4B11", "ADMIX"),
        ("HomSap", "Africa_1T12", "AFR"),
        ("HomSap", "Zigzag_1S14", "generic"),
        ("PanTro", "BonoboGhost_4K19", "bonobo"),
        ("PapAnu", "SinglePopSMCpp_1W22", "PAnubis_SNPRC"),
        ("PonAbe", "TwoSpecies_2L11", "Bornean"),
    ],
    "methods": ["smcpp", "phlash", "fitcoal", "msmc2"],
    "limits": {
        "psmc": [1, 10],
        "smcpp": [1, 10],
        "fitcoal": [10, 100],
        "msmc2": [1, 10],
    },
    "sample_sizes": [1, 10, 100],
    "num_replicates": 3,
    "length_multiplier": 1.0,
    "T": np.geomspace(1e1, 1e6, 1000),
}

H2H_PARAMS["colors"] = dict(
    zip(H2H_PARAMS["methods"], matplotlib.colormaps["Set1"].colors)
)
H2H_PARAMS['labels'] = {'smcpp': r'SMC\texttt{++}', 'msmc2': 'MSMC2', 'fitcoal': 'FitCoal', 'phlash': 'phlash', }


def get_default_mutation_rate(species_name):
    return stdpopsim.get_species(species_name).genome.mean_mutation_rate


def get_genome_length(species_name):
    species = stdpopsim.get_species(species_name)
    return sum(species.get_contig(chrom).length for chrom in get_chroms(species_name))


@cache
def get_truth(species_name, demographic_model, population):
    species = stdpopsim.get_species(species_name)
    mu = get_default_mutation_rate(species_name)
    if isinstance(demographic_model, str):
        model = species.get_demographic_model(demographic_model)
    else:
        model = demographic_model
    md = model.model.debug()
    t_min = 10.0
    t_max = max(1e5, 2 * md.epochs[-1].start_time + 1)
    assert np.isinf(md.epochs[-1].end_time)
    t = np.r_[0.0, np.geomspace(t_min, t_max, 1000)]
    if "::" in population:
        # assume two popualtions, POP1::POP2. (this is very brittle)
        pop1, pop2 = population.split("::")
        pop_dict = {pop1: 1, pop2: 1}
    else:
        pop_dict = {population: 2}
    c, _ = md.coalescence_rate_trajectory(t, pop_dict)
    eta = SizeHistory(t=t, c=c)
    true_dm = DemographicModel(eta=eta, theta=mu, rho=None)
    return true_dm


rule h2h_N0:
    output:
        r"h2h/model{i}/N0.pkl",
    run:
        i = int(wildcards.i)
        species_id, model_id, population = H2H_PARAMS["models"][i]
        species, model = _find_stdpopsim_model(species_id, model_id)
        N0 = _get_N0(model, {population: 2})
        dump_file(N0, output[0])


rule h2h_config_sim:
    input:
        r"h2h/model{i}/N0.pkl",
    output:
        r"h2h/model{i}/rep{j}/{big,(big\/)?}simulations/params.pkl",
    localrule: True
    run:
        i = int(wildcards.i)
        j = int(wildcards.j)
        species, model, population = H2H_PARAMS["models"][i]
        if wildcards.big == "big/":
            n = 1000
        else:
            assert wildcards.big == ""
            n = max(H2H_PARAMS["sample_sizes"])
        pop_dict = {population: n}
        seed = j
        N0 = load_file(input[0])
        params = dict(
            species=species,
            model=model,
            populations=pop_dict,
            seed=seed,
            N0=N0,
            length_multiplier=H2H_PARAMS["length_multiplier"],
        )
        dump_file(params, output[0])


## PSMC


def input_for_h2h_config_psmc(wc):
    i = int(wc.i)
    species, _, _ = H2H_PARAMS["models"][i]
    n = int(wc.n)
    return [
        "h2h/model{i}/rep{j}/simulations/chr%s.sample%d.psmcfa.gz" % (chrom, j)
        for chrom in get_chroms(species)
        for j in range(n)
    ]


rule h2h_config_for_psmc:
    input:
        input_for_h2h_config_psmc,
    localrule: True
    output:
        "h2h/model{i}/rep{j}/n{n}/psmc/params.pkl",
    run:
        i = int(wildcards.i)
        species, _, _ = H2H_PARAMS["models"][i]
        ret = {}
        ret["mutation_rate"] = get_default_mutation_rate(species)
        ret["input_files"] = input
        dump_file(ret, output[0])


def h2h_chroms_for(wc):
    i = int(wc.i)
    species, _, _ = H2H_PARAMS["models"][i]
    yield from get_chroms(species)


## SMCPP


def input_for_h2h_config_smcpp(wc):
    return [
        r"h2h/model{i}/rep{j}/n{n}/smcpp/chr%s.smc.gz" % chrom
        for chrom in h2h_chroms_for(wc)
    ]


rule h2h_config_for_smcpp:
    input:
        input_for_h2h_config_smcpp,
    output:
        "h2h/model{i}/rep{j}/n{n}/smcpp/params.pkl",
    localrule: True
    run:
        i = int(wildcards.i)
        species, _, _ = H2H_PARAMS["models"][i]
        ret = {}
        ret["mutation_rate"] = get_default_mutation_rate(species)
        ret["input_files"] = input
        dump_file(ret, output[0])


## PHLASH


def input_for_phlash_config(wc):
    n = int(wc.n)
    big = "big/" if n == 1000 else ""
    ret = {
        "bcf": [
            ancient(f"h2h/model{{i}}/rep{{j}}/{big}simulations/chr{chrom}.bcf")
            for chrom in h2h_chroms_for(wc)
        ]
    }
    ret["csi"] = [f + ".csi" for f in ret["bcf"]]
    return ret


rule h2h_config_for_phlash:
    input:
        unpack(input_for_phlash_config),
    output:
        r"h2h/model{i}/rep{j}/n{n}/phlash/config.pkl",
    localrule: True
    run:
        def _chrom_size(bcf):
            return cyvcf2.VCF(bcf).seqlens[0]


        chroms_sorted = sorted(input.bcf, key=_chrom_size)
        test_chrom = chroms_sorted[0]
        train_chroms = chroms_sorted[1:]
        n = int(wildcards.n)
        samples = [f"sample{i}" for i in range(n)]
        ret = {}
        ret["test_data"] = (test_chrom, samples)
        ret["train_data"] = [(chrom, samples) for chrom in train_chroms]
        i = int(wildcards.i)
        species, _, _ = H2H_PARAMS["models"][i]
        ret["mutation_rate"] = get_default_mutation_rate(species)
        dump_file(ret, output[0])


## FITCOAL


def input_for_fitcoal_config(wc):
    return [
        "h2h/model{i}/rep{j}/n{n}/chr%s.afs.txt" % chrom for chrom in h2h_chroms_for(wc)
    ]


rule h2h_config_for_fitcoal:
    input:
        input_for_fitcoal_config,
    output:
        params=r"h2h/model{i}/rep{j}/n{n}/fitcoal/params.pkl",
        afs=r"h2h/model{i}/rep{j}/n{n}/fitcoal/afs.txt",
    localrule: True
    run:
        i = int(wildcards.i)
        n = int(wildcards.n)
        species, _, _ = H2H_PARAMS["models"][i]
        L = 0
        afss = []
        for fn in input:
            with open(fn, "rt") as f:
                L += int(next(f).strip())
                afss.append(list(map(int, next(f).strip().split(" "))))
        params = {}
        afs = np.sum(afss, 0)
        with open(output.afs, "wt") as f:
            f.write(" ".join(map(str, afs[1:-1].tolist())))
        params["seed"] = int(wildcards.j)
        params["genome_length_kbp"] = L / 1e3
        params["mutation_rate_per_kb"] = 1e3 * get_default_mutation_rate(species)
        dump_file(params, output.params)


## MSMC2


def input_for_msmc2_config(wc):
    return [
        "h2h/model{i}/rep{j}/n{n}/chr%s.multihetsep.txt" % chrom
        for chrom in h2h_chroms_for(wc)
    ]


rule h2h_config_for_msmc2:
    input:
        input_for_msmc2_config,
    output:
        "h2h/model{i}/rep{j}/n{n}/msmc2/params.pkl",
    localrule: True
    run:
        i = int(wildcards.i)
        species, _, _ = H2H_PARAMS["models"][i]
        ret = {}
        ret["mutation_rate"] = get_default_mutation_rate(species)
        ret["multihet_seps"] = input
        dump_file(ret, output[0])


## PLOTTING


def input_for_h2h_figure(wc):
    i = int(wc.i)
    n = int(wc.n)
    if n == 1000:
        return {"phlash": [f"h2h/model{i}/rep0/n1000/phlash/estimates.pkl"]}
    ret = {}
    for method in H2H_PARAMS["methods"]:
        if n in H2H_PARAMS["limits"].get(method, H2H_PARAMS["sample_sizes"]):
            ret[method] = [
                f"h2h/model{i}/rep{j}/n{n}/{method}/estimates.pkl"
                for j in range(H2H_PARAMS["num_replicates"])
            ]
    return ret


rule h2h_figure:
    input:
        unpack(input_for_h2h_figure),
    output:
        f"{config['figures_path']}/h2h/model{{i}}.n{{n}}.pdf",
    localrule: True
    run:
        T = H2H_PARAMS["T"]
        i = int(wildcards.i)
        model = H2H_PARAMS["models"][i]
        fig, ax = plt.subplots()
        truth = get_truth(*model)
        cm = H2H_PARAMS["colors"]
        ax.plot(T, truth.eta(T, Ne=True), color="black")
        for method, paths in input.items():
            Nes = []
            for path in paths:
                dm = load_file(path)
                if method == "phlash":
                    # list of posterior samples from dm, take posterior median as point estimate
                    Ne = np.median(
                        [d.rescale(truth.theta).eta(T, Ne=True) for d in dm], axis=0
                    )
                else:
                    Ne = dm.rescale(truth.theta).eta(T, Ne=True)
                Nes.append(Ne)
            ax.plot(T, np.median(Nes, 0), label=method, color=cm[method], alpha=0.8)
            if len(Nes) == 1:
                continue
            for f in [np.max, np.min]:
                ax.plot(
                    T,
                    f(Nes, axis=0),
                    color=cm[method],
                    linestyle="--",
                    linewidth=0.5,
                    alpha=0.8,
                )
        ax.set_xscale("log")
        ax.set_yscale("log")
        ax.legend()
        fig.savefig(output[0])


def input_for_h2h_figure_combined(wc):
    # we don't actually use the pdfs as input, just ensures all the other inputs are
    # available
    ret = [
        f"{config['figures_path']}/h2h/model{i}.n{n}.pdf"
        for i, _ in enumerate(H2H_PARAMS["models"])
        for n in H2H_PARAMS["sample_sizes"]
    ]
    ret.extend(
        [f"{config['figures_path']}/h2h/model{{i}}.n1000.pdf" for i, _ in enumerate(H2H_PARAMS["models"])]
    )
    return ret


rule h2h_figure_combined:
    input:
        input_for_h2h_figure_combined,
    output:
        f"{config['figures_path']}/h2h/combined{{i,\\d+}}.pdf",
    localrule: True
    run:
        T = H2H_PARAMS["T"]
        i = int(wildcards.i)
        models = H2H_PARAMS["models"]


        def keyfun(mdl):
            species, dm, pop = mdl
            if isinstance(dm, str):
                return mdl
            return (species, "Constant", pop)


        mdls = sorted(models, key=keyfun)[3 * i : 3 * i + 3]
        fig, axss = plt.subplots(
            nrows=3,
            ncols=4,
            figsize=(11 - 1, 8.5 - 1),
            dpi=300,
            sharex=True,
            sharey="row",
        )
        for mdl, (ax_i, axs) in zip(mdls, enumerate(axss)):
            i = models.index(mdl)
            for n, (ax_j, ax) in zip([1, 10, 100, 1000], enumerate(axs)):
                truth = get_truth(*mdl)
                cm = H2H_PARAMS["colors"]
                ax.plot(T, truth.eta(T, Ne=True), color="black")
                for method in H2H_PARAMS["methods"]:
                    if n in H2H_PARAMS["limits"].get(method, [1, 10, 100, 1000]):
                        paths = [
                            f"h2h/model{i}/rep{j}/n{n}/{method}/estimates.pkl"
                            for j in range(H2H_PARAMS["num_replicates"])
                        ]
                        if n == 1000:
                            # I only ran 1 replicate for n=1000 because of the resources needed to simulate
                            paths = paths[:1]
                        Nes = []
                        for path in paths:
                            dm = load_file(path)
                            if method == "phlash":
                                # list of posterior samples from dm, take posterior median as point estimate
                                Ne = np.median(
                                    [
                                        d.rescale(truth.theta).eta(T, Ne=True)
                                        for d in dm
                                    ],
                                    axis=0,
                                )
                            else:
                                Ne = dm.rescale(truth.theta).eta(T, Ne=True)
                            Nes.append(Ne)
                        label = None
                        if ax_i == 0:
                            if ax_j == 0 and method == "smcpp":
                                label = r"SMC\texttt{++}"
                            elif ax_j == 1 and method == "msmc2":
                                label = "MSMC2"
                            elif ax_j == 2 and method == "fitcoal":
                                label = "FitCoal"
                            elif ax_j == 3 and method == "phlash":
                                label = "phlash"
                        ax.plot(
                            T,
                            np.mean(Nes, 0),
                            label=label,
                            color=cm[method],
                            alpha=0.8,
                        )
                        ax.legend()
                        if len(Nes) == 1:
                            assert n, method == (1000, "phlash")
                            q025, q975 = np.quantile(
                                [d.rescale(truth.theta).eta(T, Ne=True) for d in dm],
                                [0.025, 0.975],
                                axis=0,
                            )
                            ax.fill_between(T, q025, q975, color=cm[method], alpha=0.3)
                        for f in [np.max, np.min]:
                            ax.plot(
                                T,
                                f(Nes, axis=0),
                                color=cm[method],
                                linestyle="--",
                                linewidth=0.5,
                                alpha=0.8,
                            )
                ax.set_xscale("log")
                ax.set_yscale("log")
        ax.set_xlim(1e1, 1e6)
        for i, n in enumerate([1, 10, 100, 1000]):
            axss[0, i].set_title(f"$n={n}$")
        trans = mtransforms.ScaledTranslation(5/72, 5/72, fig.dpi_scale_trans)
        for j, mdl in enumerate(map(keyfun, mdls)):
            y, _ = axss[j, 0].get_ylim()
            axss[j, 0].text(0., 0., f"{mdl[0]}/{mdl[1]}", transform=axss[j, 0].transAxes + trans, fontsize=8)
        axss[0, 0].set_ylabel("$N_e(t)$")
        axss[0, 0].set_xlabel("Time (generations ago)")
        fig.tight_layout()
        fig.savefig(output[0])


def _mdl_keyfun(mdl):
    species, dm, pop = mdl
    if isinstance(dm, str):
        return mdl
    return (species, "Constant", pop)


rule h2h_table_error_entry:
    input:
        r"h2h/model{i}/rep{j}/n{n}/{method}/estimates.pkl",
    output:
        r"h2h/model{i}/rep{j}/n{n}/{method}/error.pkl",
    run:
        i = int(wildcards.i)
        j = int(wildcards.j)
        n = int(wildcards.n)
        method = wildcards.method
        mdl = H2H_PARAMS["models"][i]
        truth = get_truth(*mdl)
        dm = load_file(input[0])
        if method == "phlash":
            t = np.array(
                sorted({float(ti) for d in dm for ti in d.rescale(truth.theta).eta.t})
            )
            # list of posterior samples from dm, take posterior median as point estimate
            c = np.median([d.rescale(truth.theta).eta(t) for d in dm], axis=0)
            eta = SizeHistory(t=t, c=c)
        else:
            eta = dm.rescale(truth.theta).eta
        ret = {}
        ret["model"] = _mdl_keyfun(mdl)[1]
        ret["method"] = method
        ret["rep"] = j
        ret["n"] = n
        tvs = [float(truth.eta.tv(eta, i)) for i in range(1, n + 1)]
        ret["tv1"] = tvs[0]
        ret["tvn"] = np.mean(tvs)
        ret["l2"] = truth.eta.l2(eta, 1e6)
        dump_file(ret, output[0])


def input_for_h2h_table(wc):
    for i, model in enumerate(H2H_PARAMS["models"]):
        for j in range(H2H_PARAMS["num_replicates"]):
            for method in H2H_PARAMS["methods"]:
                for n in H2H_PARAMS["sample_sizes"]:
                    if n in H2H_PARAMS["limits"].get(
                        method, H2H_PARAMS["sample_sizes"]
                    ):
                        yield f"h2h/model{i}/rep{j}/n{n}/{method}/error.pkl"
        yield f"h2h/model{i}/rep0/n1000/phlash/error.pkl"


rule h2h_table_df:
    input:
        input_for_h2h_table,
    output:
        "tables/h2h.df.pkl",
    localrule: True
    run:
        records = list(map(load_file, input))
        df = pd.DataFrame.from_records(records)
        dump_file(df, output[0])


rule h2h_table_k:
    input:
        "tables/h2h.df.pkl",
    output:
        f"{config['figures_path']}/../tables/table_{{metric}}.tex"
    localrule: True
    script:
        "../notebooks/h2h_table.py"

rule h2h_tables:
    input:
        expand(f"{config['figures_path']}/../tables/table_{{k}}.tex", k=['l2', 'tv1', 'tvn'])

# localrule h2h_figure_combined_big:
#     input:
#         input_for_h2h_figure_combined,
#     output:
#         r"figures/h2h/big{i,\d+}.pdf"


rule plot_all_h2h_combined:
    input:
        [f"{config['figures_path']}/h2h/combined{i}.pdf" for i in range(4)]


rule plot_all_h2h:
    input:
        [
            f"{config['figures_path']}/h2h/model{i}.n{n}.pdf"
            for i in range(len(H2H_PARAMS["models"]))
            for n in H2H_PARAMS["sample_sizes"]
        ]
        + [
            f"{config['figures_path']}/h2h/model{i}.n1000.pdf"
            for i in range(len(H2H_PARAMS["models"]))
        ]
        + [f"{config['figures_path']}/h2h/combined{i}.pdf" for i in range(4)]


# ALL_OUTPUT.append(rules.plot_all_h2h.input)
ALL_OUTPUT.append("tables/h2h.df.pkl")
