import tszip
import numpy as np
import pickle
import json
import os
import os.path
import glob
import re

import phlash
from phlash.data import RawContig


def path_for_unified_chrom(chrom):
    return os.path.join(
        config["unified_path"],
        f"hgdp_tgp_sgdp_high_cov_ancients_chr{chrom}.dated.trees.tsz",
    )


def unified_chroms():
    "all chrosomal arms present in the unified dataset"
    template = "hgdp_tgp_sgdp_high_cov_ancients_chr{}.dated.trees.tsz"
    # FIXME: sh < 2.0.6 monkey-patches glob.glob, disrespecting root_dir and other args.
    # https://github.com/amoffat/sh/issues/708
    files = glob.glob(template.format("*"), root_dir=config["unified_path"])
    pattern = template.format(r"(\d+_[pq])")
    for f in files:
        m = re.match(pattern, f)
        assert m
        yield m[1]


def unified_nodes_for_pop(pop, metadata):
    i = list(metadata["populations"]).index(pop)
    (inds,) = np.where(metadata["individual_populations"] == i)
    return [tuple(metadata["individuals"][i].nodes) for i in inds]


rule metadata:
    output:
        "unified/metadata.pkl",
    run:
        chr21 = tszip.decompress(path_for_unified_chrom("21_q"))
        metadata = {
            "populations": list(chr21.populations()),
            "individual_populations": chr21.individual_populations,
            "individuals": list(chr21.individuals()),
        }
        for pop in metadata["populations"]:
            pop.metadata = json.loads(pop.metadata)
        dump_file(metadata, output[0])


checkpoint merged_metadata:
    input:
        "unified/metadata.pkl",
    output:
        "unified/merged_metadata.pkl",
    run:
        # merge same pop names
        metadata = load_file(input[0])
        merged_pops = {}
        for pop in metadata["populations"]:
            name = pop.metadata.get("description", pop.metadata["name"]).split(" ")[0]
            if name == "Colombians":
                name = "Colombian"
            merged_pops.setdefault(name, [])
            merged_pops[name].append(pop)
        merged_metadata = {}
        merged_metadata["populations"] = merged_pops
        merged_i_p = np.copy(metadata["individual_populations"])
        for i, pop in enumerate(merged_pops):
            for pop1 in merged_pops[pop]:
                merged_i_p[merged_i_p == pop1.id] = i
        merged_metadata["individual_populations"] = merged_i_p
        merged_metadata["individuals"] = metadata["individuals"]
        dump_file(merged_metadata, output[0])


checkpoint supermerged:
    input:
        "unified/metadata.pkl",
    output:
        "unified/super_merged_metadata.pkl",
    localrule: True
    run:
        metadata = load_file(input[0])
        pop_data = {}
        superpop_data = {}
        for pop in metadata["populations"]:
            d = pop.metadata
            label = d.get("region") or d.get("super_population")
            if label in ("AFR", "AFRICA"):
                label = "Africa"
            if label in ("Europe", "EUR", "WestEurasia", "EUROPE", "MIDDLE_EAST"):
                label = "Europe-Middle East"
            if label in ("EAS", "EastAsia", "EAST_ASIA"):
                label = "East Asia"
            if label == "OCEANIA":
                label = "Oceania"
            if label in ("America", "AMERICA", "AMR"):
                label = "America"
            if label in (
                "SAS",
                    "SouthAsia",
                    "CENTRAL_SOUTH_ASIA",
                    "CentralAsiaSiberia",
                ):
                label = "Central-South Asia"
            if label in ("Max Planck", "Afanasievo"):
                label = "Ancient"
            superpop_data.setdefault(label, [])
            inds = np.flatnonzero(metadata["individual_populations"] == pop.id)
            nodes = [tuple(metadata["individuals"][i].nodes) for i in inds]
            superpop_data[label].extend(nodes)
            # pop_data[pop.id] = dict(name=d["name"], label=label)
        dump_file(superpop_data, output[0])


def subsample_unified(chrom_path, nodes):
    ts = tszip.decompress(chrom_path)
    nodes_flat = np.reshape(nodes, -1)
    assert nodes_flat.size
    assert len(set(nodes_flat)) == len(nodes_flat)
    new_ts, node_map = ts.simplify(samples=nodes_flat, map_nodes=True)
    # the chromosomes are organized into different arms, however the tree sequence spans the entire
    # chromosome. so there is a big "missing" chunk which will appear as nonsegregating if we just
    # ignore it.
    # as a crude hack, just restrict to the interval containing all the sites. this will throw away
    # a few hundred flanking bps on either side, but in such a large dataset, the effect is minimal.
    pos = new_ts.tables.sites.position
    new_ts = new_ts.keep_intervals([[pos.min(), pos.max()]]).trim()
    return new_ts, node_map


rule unified_subsample:
    input:
        "unified/merged_metadata.pkl",
        "unified/super_merged_metadata.pkl",
    output:
        "unified/{population}/chr{chrom}.pkl",
    resources:
        mem_mb=12000,
        runtime=60,
    run:
        metadata = load_file(input[0])
        super_metadata = load_file(input[1])
        if wildcards.population.startswith("super/"):
            label = wildcards.population[len("super/") :]
            nodes = super_metadata[label]
        else:
            nodes = unified_nodes_for_pop(wildcards.population, metadata)
        chrom_path = path_for_unified_chrom(wildcards.chrom)
        new_ts, node_map = subsample_unified(chrom_path, nodes)
        nodes = [tuple(i.nodes) for i in new_ts.individuals()]
        c = phlash.contig(new_ts, nodes)
        d = c.get_data(100)
        rc = RawContig(**d, window_size=100)
        dump_file(rc, output[0])


rule unified_config_for_phlash:
    input:
        chroms=expand("unified/{{population}}/chr{chrom}.pkl", chrom=unified_chroms()),
        merged_metadata="unified/merged_metadata.pkl",
        super_metadata="unified/super_merged_metadata.pkl",
    output:
        "unified/{population}/phlash/config.pkl",
    localrule: True
    run:
        if wildcards.population.startswith("super/"):
            label = wildcards.population[len("super/") :]
            orig_nodes = load_file(input.super_metadata)[label]
            nodes = list(map(tuple, np.arange(2 * len(orig_nodes)).reshape(-1, 2)))
        else:
            orig_nodes = unified_nodes_for_pop(
                wildcards.population, load_file(input.merged_metadata)
            )
            nodes = np.arange(2 * len(orig_nodes)).reshape(-1, 2)
            nodes = list(map(tuple, nodes))
        params = {}
        params["test_data"] = (input.chroms[0], nodes)
        params["train_data"] = [(c, nodes) for c in input.chroms[1:]]
        params["mutation_rate"] = config["human_mutation_rate"]
        params["options"] = {"N0": 1e4}
        dump_file(params, output[0])


def input_for_unified_all(wc):
    metadata = load_file(checkpoints.merged_metadata.get().output[0])
    return {pop: f"unified/{pop}/phlash/estimates.pkl" for pop in metadata["populations"]}

rule unified_all:
    input:
        unpack(input_for_unified_all)
    output:
        f"{config['figures_path']}/unified/all.pdf",
    localrule: True
    run:
        
        fig, ax = plt.subplots(figsize=(6.5, 3), layout="constrained")
        T = np.geomspace(1e2, 1e6, 1000)
        for pop in input.keys():
            dms = load_file(input[pop])
            Nes = [d.eta(T, Ne=True) for d in dms]
            ax.plot(T*24, np.median(Nes, 0), alpha=0.03, color="black")
        ax.set_xscale('log')
        ax.set_yscale('log')
        ax.set_xlabel("Years ($g=24$)")
        ax.set_ylabel("$N_e(t)$")
        ax.set_xlim(1e2*24, 1e6*24)
        ax.axvspan(813e3, 930e3, color="grey", edgecolor=None, lw=0, alpha=.25)
        fig.savefig(output[0], bbox_inches="tight")




def input_for_unified_merged(wc):
    super_metadata = load_file(checkpoints.supermerged.get().output[0])
    ret = {
        label: f"unified/super/{label}/phlash/estimates.pkl" for label in super_metadata
    }
    ret.update({
        label: f"unified/{label}/phlash/estimates.pkl" for label in ["Yoruba", "Papuan", "Han"]
})
    ret.update({
        label: f"adna/{label}/filtered/phlash/estimates.pkl" for label in ["Altai", "Vindija", "Denisovan"]
})
    ret['all_pops'] = list(input_for_unified_all(wc).values())
    return ret


rule plot_unified_merged_helper:
    input:
        unpack(input_for_unified_merged),
    output:
        "unified/all_Ne.pkl"
    run:
        ret = {}
        T = np.geomspace(1e2, 1e6, 1000)
        for f in input.all_pops:
            dms = load_file(f)
            Nes = [d.eta(T, Ne=True) for d in dms]
            ret[f] = np.median(Nes, 0)
        dump_file(ret, output[0])
    

rule plot_unified_merged:
    input:
        unpack(input_for_unified_merged),
        preprocessed="unified/all_Ne.pkl",
    output:
        f"{config['figures_path']}/unified/merged.pdf",
    localrule: True
    run:
        import matplotlib.transforms as mtransforms
        fig, axs = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, layout="constrained", figsize=(6.5, 4))
        axs[0,0].tick_params('x', labelbottom=False)
        axs[0,1].tick_params('x', labelbottom=False)
        axs[0,1].tick_params('y', labelleft=False)
        axs[1,1].tick_params('y', labelleft=False)
        axs = axs.T
        T = np.geomspace(1e2, 1e6, 1000)
        ax = axs[0,0]
        pp = load_file(input.preprocessed)
        for f in input.all_pops:
            med_Ne = pp[f]
            ax.plot(T, med_Ne, alpha=0.05, color="black")
        ax.set_xscale('log')
        ax.set_yscale('log')
        ax.set_xlim(1e2, 1e6)
        ax.axvspan(813e3/24, 930e3/24, color="grey", edgecolor=None, lw=0, alpha=.25)


        ax = axs[1,0]
        specific = ["Han", "Yoruba", "Papuan", "Altai", "Vindija", "Denisovan"]
        keys = specific + ["Africa", "America", "Ancient", "East Asia", "Central-South Asia", "Europe-Middle East", "Oceania"]
        lines = {}
        trans = mtransforms.ScaledTranslation(0., -2/72, fig.dpi_scale_trans)
        for label in keys:
            if label in specific: continue
            dms = load_file(input[label])
            Nes = [
                d.rescale(config["human_mutation_rate"]).eta(T, Ne=True) for d in dms
            ]
            Ne = np.median(Nes, 0)
            kw = {}
            kw['label'] = label
            line, = ax.plot(T, Ne, **kw)
            c = line.get_c()
            # if label != "Ancient": continue
            from labellines import labelLine, labelLines
            # labelLine(
            #     line,
            #     x=101,
            #     label=r"Ancient",
            #     ha="left",
            #     # va="bottom",
            #     align=True,
            #     backgroundcolor="none",
            #     fontsize=8,
            # )
            # ax.text(T[0], Ne[0], label, horizontalalignment="right", verticalalignment="baseline", color=c)
        lines, labels = ax.get_legend_handles_labels()
        import matplotlib.lines
        line = matplotlib.lines.Line2D([],[],alpha=0)
        lines.insert(0, line)
        labels.insert(0, '')
        ax.legend(lines, labels, ncols=2, fontsize=8, loc="lower right")
        ax.set_xscale("log")
        ax.set_yscale("log")
        # ax.set_xlabel("Time")
        ax.set_xlim(1e2, 1e6)


        ax = axs[0,1]
        for k in sorted(["Han", "Papuan", "Yoruba"]):
            dms = load_file(input[k])
            Nes = [
                d.rescale(config["human_mutation_rate"]).eta(T, Ne=True) for d in dms
            ]
            Ne, q025, q975 = np.quantile(Nes, [0.5, 0.025, 0.975], axis=0)
            ax.plot(T, Ne, label=k)
            ax.fill_between(T, q025, q975, alpha=0.3)
        ax.legend(loc="lower right")
        # ax.set_xlabel("Time")


        ax = axs[1,1]
        for k in sorted(["Vindija", "Altai", "Denisovan"]):
            dms = load_file(input[k])
            Nes = [
                d.rescale(config["human_mutation_rate"]).eta(T, Ne=True) for d in dms
            ]
            Ne, q025, q975 = np.quantile(Nes, [0.5, 0.025, 0.975], axis=0)
            ax.plot(T, Ne, label=k)
            ax.fill_between(T, q025, q975, alpha=0.3)
        ax.legend(loc="lower right")
        # ax.legend(ncols=3, loc="lower right")
        # ax.set_xlabel("Time")

        trans = mtransforms.ScaledTranslation(-10/72, -7/72, fig.dpi_scale_trans)
        for ax, lbl in zip(axs.T.reshape(-1), "abcd"):
            ax.text(1., 1., f"({lbl})", transform=ax.transAxes + trans, horizontalalignment="right", verticalalignment="top")
        fig.supxlabel("Time", fontsize=12)
        fig.supylabel("$N_e(t)$", fontsize=12)
        fig.savefig(output[0], bbox_inches="tight")


# ALL_OUTPUT.extend(rules.unified_all.output)
# ALL_OUTPUT.extend(rules.unified_merged.output)
