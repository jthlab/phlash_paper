import tszip
import numpy as np
import pickle
import json
import os
import os.path
import glob
import re

import phlash
from phlash.data import RawContig


def path_for_unified_chrom(chrom):
    return os.path.join(
        config["unified_path"],
        f"hgdp_tgp_sgdp_high_cov_ancients_chr{chrom}.dated.trees.tsz",
    )


def unified_chroms():
    "all chrosomal arms present in the unified dataset"
    template = "hgdp_tgp_sgdp_high_cov_ancients_chr{}.dated.trees.tsz"
    # FIXME: sh < 2.0.6 monkey-patches glob.glob, disrespecting root_dir and other args.
    # https://github.com/amoffat/sh/issues/708
    files = glob.glob(template.format("*"), root_dir=config["unified_path"])
    pattern = template.format(r"(\d+_[pq])")
    for f in files:
        m = re.match(pattern, f)
        assert m
        yield m[1]


def unified_nodes_for_pop(pop, metadata):
    i = list(metadata["populations"]).index(pop)
    (inds,) = np.where(metadata["individual_populations"] == i)
    return [tuple(metadata["individuals"][i].nodes) for i in inds]


rule metadata:
    output:
        "unified/metadata.pkl",
    run:
        chr21 = tszip.decompress(path_for_unified_chrom("21_q"))
        metadata = {
            "populations": list(chr21.populations()),
            "individual_populations": chr21.individual_populations,
            "individuals": list(chr21.individuals()),
        }
        for pop in metadata["populations"]:
            pop.metadata = json.loads(pop.metadata)
        dump_file(metadata, output[0])


checkpoint merged_metadata:
    input:
        "unified/metadata.pkl",
    output:
        "unified/merged_metadata.pkl",
    run:
        # merge same pop names
        metadata = load_file(input[0])
        merged_pops = {}
        for pop in metadata["populations"]:
            name = pop.metadata.get("description", pop.metadata["name"]).split(" ")[0]
            if name == "Colombians":
                name = "Colombian"
            merged_pops.setdefault(name, [])
            merged_pops[name].append(pop)
        merged_metadata = {}
        merged_metadata["populations"] = merged_pops
        merged_i_p = np.copy(metadata["individual_populations"])
        for i, pop in enumerate(merged_pops):
            for pop1 in merged_pops[pop]:
                merged_i_p[merged_i_p == pop1.id] = i
        merged_metadata["individual_populations"] = merged_i_p
        merged_metadata["individuals"] = metadata["individuals"]
        dump_file(merged_metadata, output[0])


checkpoint supermerged:
    input:
        "unified/metadata.pkl",
    output:
        "unified/super_merged_metadata.pkl",
    localrule: True
    run:
        metadata = load_file(input[0])
        pop_data = {}
        superpop_data = {}
        for pop in metadata["populations"]:
            d = pop.metadata
            label = d.get("region") or d.get("super_population")
            if label in ("AFR", "AFRICA"):
                label = "Africa"
            if label in ("Europe", "EUR", "WestEurasia", "EUROPE", "MIDDLE_EAST"):
                label = "Europe-Middle East"
            if label in ("EAS", "EastAsia", "EAST_ASIA"):
                label = "East Asia"
            if label == "OCEANIA":
                label = "Oceania"
            if label in ("America", "AMERICA", "AMR"):
                label = "America"
            if label in (
                "SAS",
                    "SouthAsia",
                    "CENTRAL_SOUTH_ASIA",
                    "CentralAsiaSiberia",
                ):
                label = "Central-South Asia"
            if label in ("Max Planck", "Afanasievo"):
                label = "Ancient"
            superpop_data.setdefault(label, [])
            inds = np.flatnonzero(metadata["individual_populations"] == pop.id)
            nodes = [tuple(metadata["individuals"][i].nodes) for i in inds]
            superpop_data[label].extend(nodes)
            # pop_data[pop.id] = dict(name=d["name"], label=label)
        dump_file(superpop_data, output[0])


def subsample_unified(chrom_path, nodes):
    ts = tszip.decompress(chrom_path)
    nodes_flat = np.reshape(nodes, -1)
    assert nodes_flat.size
    assert len(set(nodes_flat)) == len(nodes_flat)
    new_ts, node_map = ts.simplify(samples=nodes_flat, map_nodes=True)
    # the chromosomes are organized into different arms, however the tree sequence spans the entire
    # chromosome. so there is a big "missing" chunk which will appear as nonsegregating if we just
    # ignore it.
    # as a crude hack, just restrict to the interval containing all the sites. this will throw away
    # a few hundred flanking bps on either side, but in such a large dataset, the effect is minimal.
    pos = new_ts.tables.sites.position
    new_ts = new_ts.keep_intervals([[pos.min(), pos.max()]]).trim()
    return new_ts, node_map


rule unified_subsample:
    input:
        "unified/merged_metadata.pkl",
        "unified/super_merged_metadata.pkl",
    output:
        "unified/{population}/chr{chrom}.pkl",
    resources:
        mem_mb=12000,
        runtime=60,
    run:
        metadata = load_file(input[0])
        super_metadata = load_file(input[1])
        if wildcards.population.startswith("super/"):
            label = wildcards.population[len("super/") :]
            nodes = super_metadata[label]
        else:
            nodes = unified_nodes_for_pop(wildcards.population, metadata)
        chrom_path = path_for_unified_chrom(wildcards.chrom)
        new_ts, node_map = subsample_unified(chrom_path, nodes)
        nodes = [tuple(i.nodes) for i in new_ts.individuals()]
        c = phlash.contig(new_ts, nodes)
        d = c.get_data(100)
        rc = RawContig(**d, window_size=100)
        dump_file(rc, output[0])


rule unified_config_for_phlash:
    input:
        chroms=expand("unified/{{population}}/chr{chrom}.pkl", chrom=unified_chroms()),
        merged_metadata="unified/merged_metadata.pkl",
        super_metadata="unified/super_merged_metadata.pkl",
    output:
        "unified/{population}/phlash/config.pkl",
    localrule: True
    run:
        if wildcards.population.startswith("super/"):
            label = wildcards.population[len("super/") :]
            orig_nodes = load_file(input.super_metadata)[label]
            nodes = list(map(tuple, np.arange(2 * len(orig_nodes)).reshape(-1, 2)))
        else:
            orig_nodes = unified_nodes_for_pop(
                wildcards.population, load_file(input.merged_metadata)
            )
            nodes = np.arange(2 * len(orig_nodes)).reshape(-1, 2)
            nodes = list(map(tuple, nodes))
        params = {}
        params["test_data"] = (input.chroms[0], nodes)
        params["train_data"] = [(c, nodes) for c in input.chroms[1:]]
        params["mutation_rate"] = config["human_mutation_rate"]
        params["options"] = {"N0": 1e4}
        dump_file(params, output[0])


def input_for_unified_all(wc):
    metadata = load_file(checkpoints.merged_metadata.get().output[0])
    return expand(
        "unified/{population}/phlash/estimates.pkl", population=metadata["populations"]
    )


rule unified_all:
    input:
        input_for_unified_all,
    output:
        "figures/unified/plot.pdf",


def input_for_unified_merged(wc):
    super_metadata = load_file(checkpoints.supermerged.get().output[0])
    return {
        label: f"unified/super/{label}/phlash/estimates.pkl" for label in super_metadata
    }


rule unified_merged:
    input:
        unpack(input_for_unified_merged),
    output:
        f"{config['figures_path']}/unified/merged.pdf",
    localrule: True
    run:
        # Desired canvas size
        canvas_width, canvas_height = 6.5, 2  # in inches

        # Estimate extra space for margins - you may need to adjust these
        left_margin = 0.1  # Fraction of figure width
        right_margin = 0.05  # Fraction of figure width
        bottom_margin = 0.1  # Fraction of figure height
        top_margin = 0.1  # Fraction of figure height

        # Calculate figure size
        figure_width = canvas_width / (1 - left_margin - right_margin)
        figure_height = canvas_height / (1 - bottom_margin - top_margin)
        fig, ax = plt.subplots(
            dpi=300, figsize=(figure_width, figure_height), tight_layout=True
        )
        T = np.geomspace(1e1, 1e6, 1000)
        for label in input.keys():
            dms = load_file(input[label])
            Nes = [
                d.rescale(config["human_mutation_rate"]).eta(T, Ne=True) for d in dms
            ]
            Ne = np.median(Nes, 0)
            ax.plot(T, Ne, label=label)
        ax.legend(ncols=4, loc="lower right")
        ax.set_xscale("log")
        ax.set_yscale("log")
        ax.set_xlabel("Time (generations)")
        ax.set_ylabel("$N_e(t)$")
        ax.set_xlim(1e1, 1e6)
        fig.tight_layout()
        fig.savefig(output[0])


# ALL_OUTPUT.extend(rules.unified_all.output)
ALL_OUTPUT.extend(rules.unified_merged.output)
